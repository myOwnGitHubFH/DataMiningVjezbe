{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c461484-a013-46aa-bc7b-4e4a74ae7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e405d47-ddb3-4337-9241-c124d0f7a72a",
   "metadata": {},
   "source": [
    "# Neke dodatne tranformacije podataka samo za resnet\n",
    "Definiraju se dvije grupe transformacija: \n",
    "*train_tf* za trening skup podataka i \n",
    "*val_tf* za validacioni skup podataka. \n",
    "Prvi uključuje augmentaciju podataka poput nasumičnog izrezivanja, rotacije, promjene boja, sivih tonova i horizontalnog preokretanja. Drugi koristi samo promjenu veličine i centralno izrezivanje. Obje transformacije normalizuju pikselne vrijednosti slika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387ca96-2840-4798-8b30-9ae53135f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5,1.0), ratio=(0.75,1.33)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std =[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497d377-d367-4d1b-b60b-a186f915eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d9072-edf1-41bd-9ec2-2f0f09be95f3",
   "metadata": {},
   "source": [
    "Slijedi učitavanje trening i validacionog skupa podataka\n",
    "Zatim se kreiraju DataLoader objekti (train_loader i val_loader) za efikasno učitavanje podataka u serijama (batch-evima) tokom treninga i validacije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9853a-ba77-4f64-afe0-1366b415ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(r\"F:\\projekt13\\data_changed\\train\", transform=train_tf)\n",
    "val_ds   = ImageFolder(r\"F:\\projekt13\\data_changed\\val\",   transform=val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598ef94-fcbf-4d2c-ae0d-455e630d78c0",
   "metadata": {},
   "source": [
    "torch i torch.nn module za rad sa PyTorch tensorima i neuronskim mrežama.\n",
    "\n",
    "resnet18 model i ResNet18_Weights iz torchvision.models za korištenje preobučenog ResNet-18 modela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e869a33-3dd1-4ee8-92b1-4de54704c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb5ebf-d46e-4f34-88e7-38312ae2a81c",
   "metadata": {},
   "source": [
    "Ovdje prvo provjeravamo imamo li jaku grafičku karticu (GPU) na računaru. Ako imamo, koristit ćemo nju jer je puno brža za ove stvari. Ako ne, onda ćemo raditi na običnom procesoru (CPU).\n",
    "\n",
    "Zatim, uzimamo ResNet-18.Pošto naš model treba da prepoznaje specifične stvari (naših koliko već klasa imamo), moramo mu promijeniti zadnji dio(ovo ide po layerima). Ovdje je namjesteno da uči samo zadnji dio i pretposljednji sloj (layer4), da ne zaboravi ono što je već naučio, ali da se prilagodi našim slikama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52905375-79da-4112-a580-f3919659ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# fine-tune only layer4 \n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = name.startswith(\"layer4.\") or name.startswith(\"fc.\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66440e-a981-4d5e-9d2b-8ceaa57a5cee",
   "metadata": {},
   "source": [
    "Prvo, opet kažemo modelu da na početku uči samo onaj zadnji sloj koji smo promijenili. \n",
    "Onda mu dajemo \"uputstva\" kako da se poboljšava – to je optimizer. Korisen je Adam.\n",
    "Imamo i \"planera učenja\" (scheduler). To znači da će se brzina učenja smanjivati svakih pet epoha (ciklusa učenja) kako bi model finije prilagodio svoje znanje.\n",
    "I na kraju, trebamo način da izmjerimo koliko model griješi. Za to koristimo CrossEntropyLoss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a29bf25-abe2-4d74-b99c-c908124af6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Initially freeze all except fc\n",
    "for name,param in model.named_parameters():\n",
    "    param.requires_grad = name.startswith(\"fc.\")\n",
    "\n",
    "# 5.2 Optimizer: head only\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-3, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# 5.3 LR scheduler: step down every 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bb657-3f0e-430c-a909-1e679b1d7fd9",
   "metadata": {},
   "source": [
    "### Inicijalizacija varijabli za trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d7f66-4255-4f54-a6bf-695b6a3ea147",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "num_epochs   = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2f9a5-f0d3-441d-a8af-9d69426a44d1",
   "metadata": {},
   "source": [
    "### Trening i validacija\n",
    "\n",
    "- Model se postavlja u režim treninga (model.train()).\n",
    "- Izračunava se gubitak i tačnost na trening skupu.\n",
    "- Optimizator se resetuje, izvodi se propagacija unazad i ažuriraju se težine modela.\n",
    "- Planer brzine učenja se ažurira.\n",
    "- Model se postavlja u režim evaluacije (model.eval()).\n",
    "- Izračunava se tačnost na validacionom skupu bez izračunavanja gradijenata.\n",
    "- Ispisuje se tačnost treninga i validacije za trenutnu epohu.\n",
    "- U epohi 3, parametri layer4 i fc se otključavaju, a optimizator i planer brzine učenja se rekonfigurišu sa nižom brzinom učenja.\n",
    "- Ako je validaciona tačnost bolja od prethodne najbolje, model se spašava."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182a992-769b-4bb9-8f27-24968b0b6d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc 0.185, Val Acc 0.261\n",
      "✔ New best saved\n",
      "Epoch 2: Train Acc 0.308, Val Acc 0.348\n",
      "✔ New best saved\n",
      "Epoch 3: Train Acc 0.415, Val Acc 0.507\n",
      "✔ New best saved\n",
      "Epoch 4: Train Acc 0.518, Val Acc 0.623\n",
      "✔ New best saved\n",
      "Epoch 5: Train Acc 0.585, Val Acc 0.797\n",
      "✔ New best saved\n",
      "Epoch 6: Train Acc 0.769, Val Acc 0.899\n",
      "✔ New best saved\n",
      "Epoch 7: Train Acc 0.805, Val Acc 0.957\n",
      "✔ New best saved\n",
      "Epoch 8: Train Acc 0.872, Val Acc 0.971\n",
      "✔ New best saved\n",
      "Epoch 9: Train Acc 0.913, Val Acc 0.971\n",
      "Epoch 10: Train Acc 0.903, Val Acc 0.971\n",
      "Epoch 11: Train Acc 0.923, Val Acc 0.971\n",
      "Epoch 12: Train Acc 0.903, Val Acc 0.971\n",
      "Epoch 13: Train Acc 0.887, Val Acc 0.971\n",
      "Epoch 14: Train Acc 0.933, Val Acc 0.971\n",
      "Epoch 15: Train Acc 0.908, Val Acc 0.971\n",
      "Epoch 16: Train Acc 0.938, Val Acc 0.971\n",
      "Epoch 17: Train Acc 0.918, Val Acc 0.971\n",
      "Epoch 18: Train Acc 0.938, Val Acc 0.971\n",
      "Epoch 19: Train Acc 0.908, Val Acc 0.971\n",
      "Epoch 20: Train Acc 0.892, Val Acc 0.971\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = train_correct = total = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss   = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss    += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        total         += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # — Validation —\n",
    "    model.eval()\n",
    "    val_correct = val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            preds  = logits.argmax(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total   += labels.size(0)\n",
    "\n",
    "    train_acc = train_correct/total\n",
    "    val_acc   = val_correct/val_total\n",
    "    print(f\"Epoch {epoch+1}: Train Acc {train_acc:.3f}, Val Acc {val_acc:.3f}\")\n",
    "\n",
    "    # On plateau, unfreeze layer4 & lower LR\n",
    "    if epoch == 3:\n",
    "        for name,param in model.named_parameters():\n",
    "            if name.startswith(\"layer4.\") or name.startswith(\"fc.\"):\n",
    "                param.requires_grad = True\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=1e-4, weight_decay=1e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    # Save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"F:/projekt13/best_resnet18_ft.pth\")\n",
    "        print(\"✔ New best saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f639936-fbfa-48a3-90dd-986cb9532625",
   "metadata": {},
   "source": [
    "### Test modela na nekoj konkretnoj slici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92435d6-64c4-411f-9d1a-2b3d95143738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: jerry_seinfeld  (74.7% confident)\n"
     ]
    }
   ],
   "source": [
    "# Rebuild & load\n",
    "model = models.resnet18(weights= None)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"F:/projekt13/best_resnet18_ft.pth\", map_location=device))\n",
    "model.to(device).eval()\n",
    "\n",
    "# Preprocess test images\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),])\n",
    "\n",
    "def predict(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    inp = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inp)\n",
    "        prob   = torch.softmax(logits, 1)\n",
    "        idx    = prob.argmax(1).item()\n",
    "        return train_ds.classes[idx], prob[0, idx].item()\n",
    "\n",
    "img_path = r\"F:\\projekt13\\MV5BNTFjZDU5NmYtYzZlMy00YThmLTg5ZjUtYjkyZWI2OTk2Mjc1XkEyXkFqcGc@._V1_FMjpg_UX1000_.jpg\"\n",
    "label, conf = predict(img_path)\n",
    "print(f\"Prediction: {label}  ({conf*100:.1f}% confident)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
