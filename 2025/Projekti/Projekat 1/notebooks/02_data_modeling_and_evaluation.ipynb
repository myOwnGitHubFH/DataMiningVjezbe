{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Advanced Regression - Modeling Notebook\n",
    "## XGBoost i Random Forest Implementacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prije nego što počnemo s modeliranjem, potrebno je uvesti sve potrebne biblioteke. Ovo uključuje osnovne pakete za analizu podataka kao što su numpy i pandas za manipulaciju podacima, matplotlib i seaborn za vizualizaciju, te scikit-learn za mašinsko učenje. Posebno uvozimo ensemble metode (RandomForest i XGBoost) zajedno s metrikama za evaluaciju modela i alatima za preprocesiranje. Postavljamo filter za upozorenja da ignoriše nebitne poruke kako bi notebook bio čistiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Učitavanje prerađenih podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ćemo učitati preprocesirane podatke koji su pripremljeni u fazi čišćenja podataka i inženjeringa obilježja. Podaci su podijeljeni na obilježja za trening (X_train), ciljnu varijablu za trening (y_train) i obilježja za testiranje (X_test). Koristimo try-except blokove za rukovanje eventualnim greškama pri učitavanju datoteka i dajemo informativne poruke o obliku svakog skupa podataka kako bismo potvrdili uspješno učitavanje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train = pd.read_csv('../processed_data/X_train_processed.csv')\n",
    "    y_train = pd.read_csv('../processed_data/y_train.csv').values.ravel()\n",
    "    X_test = pd.read_csv('../processed_data/X_test_processed.csv')\n",
    "    print(\"Podaci uspješno učitani!\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Greška pri učitavanju podataka: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Podjela na trening i validacioni skup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prije treniranja modela, potrebno je podijeliti trening podatke na trening i validacione skupove. Ovaj validacioni skup će nam pomoći da evaluiramo performanse modela tokom razvoja bez dodirivanja stvarnog testnog skupa. Koristimo podjelu 70-30, sa 30% podataka rezervisanih za validaciju. Parametar random_state osigurava reproduktivne rezultate pri svakom pokretanju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"\\nPodjela podataka:\")\n",
    "print(f\"Trening skup: {X_train.shape}\")\n",
    "print(f\"Validacioni skup: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Metrike evaluacije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pravilnu procjenu naših modela, potrebne su sveobuhvatne metrike evaluacije. Ova funkcija izračunava i prikazuje više metrika uključujući MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), RMSLE (Root Mean Squared Logarithmic Error - posebno korisno za predviđanje cijena kuća gdje su nam bitne relativne greške) i R² skor. Funkcija formatira izlaz uredno i vraća metrike za kasnije poređenje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"\"):\n",
    "    \"\"\"Izračunaj i prikaži metrike evaluacije\"\"\"\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'RMSLE': np.sqrt(mean_squared_error(np.log1p(y_true), np.log1p(y_pred))),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Metrike:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Počet ćemo sa Random Forest modelom, koji je ansambl stabala odluka koji obično pruža dobre performanse uz minimalno podešavanje. Kreiramo pipeline koji prvo standardizuje obilježja (skalira ih da imaju nultu srednju vrijednost i jediničnu varijansu) a zatim primjenjuje Random Forest regresor. GridSearchCV će nam pomoći da pronađemo optimalne hiperparametre testiranjem različitih kombinacija n_estimators (broj stabala), max_depth (dubina stabla) i parametara za podjelu uzoraka. Koristimo negativnu srednju kvadratnu grešku kao našu metriku skorovanja jer je konvencija scikit-learn-a da se maksimiziraju skorovi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "rf_params = {\n",
    "    'randomforestregressor__n_estimators': [100, 200],\n",
    "    'randomforestregressor__max_depth': [None, 10, 20],\n",
    "    'randomforestregressor__min_samples_split': [2, 5],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=rf_params,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTreniranje Random Forest modela...\")\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rf_grid.best_estimator_\n",
    "print(\"\\nNajbolji parametri za Random Forest:\")\n",
    "print(rf_grid.best_params_)\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_val)\n",
    "rf_metrics = evaluate_model(y_val, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. RF Značajnost obilježja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razumijevanje koja su obilježja najvažnija u našem Random Forest modelu pomaže u interpretaciji i potencijalnoj selekciji obilježja. Vrijednosti značajnosti obilježja predstavljaju koliko svako obilježje doprinosi smanjenju nečistoće u svim stablima u šumi. Vizualiziramo top 20 obilježja koristeći horizontalni bar plot za lakše poređenje. Ovo može otkriti zanimljive uvide o tome koji faktori najviše utiču na cijene kuća prema našem modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_imp = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_rf.named_steps['randomforestregressor'].feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=rf_feature_imp.head(20))\n",
    "plt.title('Top 20 obilježja - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost (Extreme Gradient Boosting) je moćan algoritam za poboljšanje koji često daje bolje rezultate od Random Forest-a. Slično kao ranije, kreiramo pipeline sa standardizacijom i XGBRegressor-om. Mreža hiperparametara uključuje learning rate (koliko brzo se model adaptira), maksimalnu dubinu stabla i parametre za poduzorkovanje kako bismo spriječili prenaučenost. Koristimo 'reg:squarederror' kao cilj jer je ovo problem regresije. GridSearchCV će pronaći najbolju kombinaciju ovih parametara kroz unakrsnu validaciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror')\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'xgbregressor__n_estimators': [100, 200],\n",
    "    'xgbregressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'xgbregressor__max_depth': [3, 5, 7],\n",
    "    'xgbregressor__subsample': [0.8, 1.0],\n",
    "    'xgbregressor__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_grid=xgb_params,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTreniranje XGBoost modela...\")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "print(\"\\nNajbolji parametri za XGBoost:\")\n",
    "print(xgb_grid.best_params_)\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_val)\n",
    "xgb_metrics = evaluate_model(y_val, y_pred_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. XGBoost Značajnost obilježja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slično analizi za Random Forest, ispitujemo značajnost obilježja za XGBoost. XGBoost izračunava značajnost na osnovu toga koliko često se obilježje koristi za podjelu podataka u svim stablima, ponderisano poboljšanjem u ciljnoj funkciji. Poređenje ovih važnih obilježja sa onima iz Random Forest-a može otkriti dosljedne obrasce ili zanimljive razlike u tome kako dva modela uče iz podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feature_imp = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_xgb.named_steps['xgbregressor'].feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=xgb_feature_imp.head(20))\n",
    "plt.title('Top 20 obilježja - XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Poređenje modela i ansambl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ćemo uporediti performanse naša dva modela i istražiti kreiranje jednostavnog ansambla prosječnim predviđanjem. Ansamblovanje često može poboljšati performanse kombinovanjem prednosti različitih modela. Kreiramo DataFrame za uredan prikaz svih metrika jedna pored druge za lakše poređenje. RMSLE (Root Mean Squared Logarithmic Error) je posebno važan za ovo takmičenje jer je službena metrika evaluacije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = (y_pred_rf + y_pred_xgb) / 2\n",
    "ensemble_metrics = evaluate_model(y_val, y_pred_ensemble, \"Ensemble (RF + XGB)\")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Random Forest': rf_metrics,\n",
    "    'XGBoost': xgb_metrics,\n",
    "    'Ensemble': ensemble_metrics\n",
    "}).T\n",
    "\n",
    "print(\"\\nPoređenje modela:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Vizualizacija predviđanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizacija stvarnih naspram predviđenih vrijednosti pomaže nam da razumijemo koliko dobro naši modeli rade u različitim rasponima cijena. Kreiramo scatter plot koji upoređuje predviđanja oba modela sa stvarnim vrijednostima, sa crvenom isprekidanom linijom koja predstavlja savršena predviđanja. Ova vizualizacija može otkriti da li naši modeli imaju dosljedne obrasce grešaka kroz spektar cijena ili bolje rade u određenim rasponima cijena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_val, y_pred_xgb, alpha=0.5, label='XGBoost')\n",
    "plt.scatter(y_val, y_pred_rf, alpha=0.5, label='Random Forest')\n",
    "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'r--', label='Savršeno predviđanje')\n",
    "plt.xlabel('Stvarne cijene')\n",
    "plt.ylabel('Predviđene cijene')\n",
    "plt.title('Stvarne vs predviđene cijene kuća')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Treniranje finalnog modela na kompletnim trening podacima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon evaluacije naših modela na validacionom skupu, treniraćemo naš konačni model (XGBoost, koji je imao bolje performanse) na cijelom trening skupu podataka (kombinujući naše prethodne trening i validacione skupove). Ovo daje modelu više podataka za učenje i trebalo bi poboljšati njegovu sposobnost generalizacije. Koristimo najbolje hiperparametre pronađene tokom naše pretrage mreže."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBRegressor(\n",
    "        **{k.replace('xgbregressor__', ''): v for k, v in xgb_grid.best_params_.items()},\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nTreniranje finalnog modela na kompletnim trening podacima...\")\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Predviđanje na testnom skupu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa našim finalnim modelom istreniranim, sada možemo generisati predviđanja za stvarni testni skup. Ova predviđanja će biti korištena za naše takmičarsko podnošenje. Važno je napomenuti da nismo dodirivali ovaj testni skup tokom bilo kojeg dijela našeg procesa razvoja modela kako bismo osigurali nepristrasnu evaluaciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Priprema fajla za podnošenje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatiraćemo naša predviđanja u traženi format za podnošenje, koji očekuje ID kolonu koja odgovara ID-ovima testnog skupa i naše predviđene SalePrice vrijednosti. ID-ovi počinju od 1461 jer je ovo nastavak trening skupa. Čuvamo ovo u CSV fajl u našem processed_data direktoriju za podnošenje na platformu takmičenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': range(1461, 1461 + len(X_test)),\n",
    "    'SalePrice': test_predictions\n",
    "})\n",
    "\n",
    "submission_path = '../processed_data/submission_final.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nFajl za podnošenje sačuvan na: {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Unakrsna validacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da bismo dobili robusniju procjenu performansi našeg modela, vršimo k-fold unakrsnu validaciju na cijelom trening skupu. Ovo nam daje više procjena performansi rotirajući koji dijelovi podataka služe kao validacioni skupovi. Računamo i srednju vrijednost i standardnu devijaciju RMSE skorova kroz foldove da bismo razumjeli i očekivane performanse i njihovu varijabilnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(model, X, y, cv=5):\n",
    "    \"\"\"Izvrši unakrsnu validaciju i prikaži rezultate\"\"\"\n",
    "    scores = cross_val_score(\n",
    "        model, X, y, \n",
    "        cv=cv, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    \n",
    "    print(f\"\\nRezultati {cv}-fold unakrsne validacije:\")\n",
    "    print(f\"Srednji RMSE: {rmse_scores.mean():.4f}\")\n",
    "    print(f\"Std devijacija: {rmse_scores.std():.4f}\")\n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "# Izvrši CV na finalnom modelu\n",
    "cv_scores = cross_validate_model(final_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Analiza reziduala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza reziduala (razlika između stvarnih i predviđenih vrijednosti) pomaže u dijagnostici potencijalnih problema sa našim modelom. Kreiramo dva grafikona: histogram reziduala da provjerimo da li su normalno distribuirani (kao što bismo željeli), i scatter plot reziduala naspram predviđenih vrijednosti da provjerimo heteroskedastičnost (nekonstantnu varijansu). Obrasci u ovim graficima mogu sugerisati potrebu za različitim pristupima modeliranja ili transformacijama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_val - y_pred_xgb\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribucija reziduala')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred_xgb, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predviđene vrijednosti')\n",
    "plt.ylabel('Reziduali')\n",
    "plt.title('Reziduali vs predviđene vrijednosti')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Zaključak - Konačno poređenje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Završavamo prikazom naših konačnih metrika poređenja modela i identifikacijom najboljeg modela na osnovu RMSLE. Ovaj sveobuhvatni pregled pomaže da sumiramo naše napore u modeliranju i opravdamo izbor finalnog modela. Poruka o završetku potvrđuje da su svi koraci uspješno izvršeni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKonačno poređenje modela:\")\n",
    "print(metrics_df)\n",
    "\n",
    "best_model = metrics_df['RMSLE'].idxmin()\n",
    "print(f\"\\nNajbolji model na osnovu RMSLE: {best_model}\")\n",
    "print(f\"RMSLE: {metrics_df.loc[best_model, 'RMSLE']:.4f}\")\n",
    "\n",
    "print(\"\\nProces modeliranja uspješno završen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}